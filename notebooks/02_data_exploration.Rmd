---
title: "MM923 Data Analytics in R - Part 2: Exploring the Data"
author: "Nathan Ormond"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: united
    highlight: tango
    code_folding: show
    df_print: paged
---

# MM923 Data Analytics in R - Part 2: Exploring the Data

This notebook contains code and documentation for exploratory data analysis of the weather data. It addresses the second part of the assignment (20 marks).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Set working directory to project root using relative path
knitr::opts_knit$set(root.dir = here::here())
source(here::here("R", "functions.R"))
```

## Load Packages and Data

```{r load-packages-data-setup}
# Load required packages
library(tidyverse)
library(ggplot2)
library(usmap)
library(sf)
library(lmtest)
library(car)
library(here)
library(moments)
library(brms)
library(tidybayes)
library(patchwork)

# Source helper functions
source(here::here("R", "functions.R"))

# Set working directory to project root
setwd(here::here())
```

```{r load-packages-data-load}
# Load the cleaned data
weather_data <- readRDS("data/processed/weather_clean.rds")
```

```{r histogram-temp}
# Temperature distribution
ggplot(weather_data, aes(x = avg_temp)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "black") +
  labs(title = "Distribution of Average Temperatures",
       x = "Average Temperature (°F)",
       y = "Count") +
  theme_minimal()
```

```{r histogram-precip}
# Precipitation distribution
ggplot(weather_data, aes(x = avg_annual_precip)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "black") +
  labs(title = "Distribution of Annual Precipitation",
       x = "Annual Precipitation (inches)",
       y = "Count") +
  theme_minimal()
```

```{r correlation-analysis-matrix}
# Correlation matrix for numerical variables
cor_matrix <- weather_data %>%
  dplyr::select(avg_temp, avg_annual_precip, elevation, distance_to_coast, wind) %>%
  cor()

corrplot::corrplot(cor_matrix, method = "circle", type = "upper")
```

```{r correlation-analysis-pairs}
# Pairwise scatter plots
pairs(weather_data %>% dplyr::select(avg_temp, avg_annual_precip, elevation, distance_to_coast, wind))
```

```{r temp-koppen-relationship-box}
# Temperature by Köppen climate type
ggplot(weather_data, aes(x = koppen, y = avg_temp)) +
  geom_boxplot() +
  labs(title = "Temperature Distribution by Köppen Climate Type",
       x = "Köppen Climate Type",
       y = "Average Temperature (°F)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r temp-koppen-relationship-violin}
# Enhanced violin plot for temperature by Köppen climate type
ggplot(weather_data, aes(x = reorder(koppen, avg_temp, FUN = median), 
                        y = avg_temp, 
                        fill = koppen)) +
  geom_violin(alpha = 0.7, scale = "width") +
  geom_boxplot(width = 0.2, alpha = 0.5, fill = "white") +  # Add boxplot inside violin
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3, 
              fill = "white", color = "black") +  # Add mean point
  labs(
    title = "Temperature Distribution by Köppen Climate Classification",
    subtitle = "Violin plot with embedded boxplot and mean (diamond)",
    x = "Köppen Climate Type",
    y = "Average Temperature (°F)"
  ) +
  scale_fill_viridis_d(option = "D", guide = "none") +  # Use viridis color palette
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 12),
    plot.subtitle = element_text(hjust = 0.5, size = 10),
    axis.title = element_text(face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
    panel.grid.major.x = element_blank(),
    panel.border = element_rect(fill = NA, color = "gray80")
  ) +
  coord_cartesian(clip = "off")  # Prevent clipping of violin plots
```

```{r count-koppen-a-table}
# Count of Köppen A climate types
weather_data %>%
  filter(str_detect(koppen, "^A")) %>%
  count(koppen) %>%
  arrange(desc(n))
```

```{r count-koppen-a-plot}
# Bar plot of Köppen A climate types
weather_data %>%
  filter(str_detect(koppen, "^A")) %>%
  count(koppen) %>%
  ggplot(aes(x = koppen, y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Count of Köppen A Climate Types",
       x = "Köppen Climate Type",
       y = "Count") +
  theme_minimal()
```

```{r state-summary-function-define}
# Function to create state summary
create_state_summary <- function(data) {
  data %>%
    group_by(State) %>%
    summarise(
      avg_temp = mean(avg_temp),
      avg_precip = mean(avg_annual_precip),
      n_cities = n(),
      .groups = "drop"
    )
}
```

```{r state-summary-function-apply}
# Apply state summary function
state_summary <- create_state_summary(weather_data)
print(state_summary)
```

---

## Average Temperature
- (a) Provide a histogram of the average temperature and provide suitable measures of location and spread.

### Histogram of average temperature 

```{r histogram}
# Create histogram of average temperature
ggplot(weather_data, aes(x = avg_temp)) +
  geom_histogram(binwidth = 2, fill = "steelblue", color = "white", alpha = 0.7) +
  labs(
    title = "Distribution of Average Temperatures Across US Cities",
    x = "Average Temperature (°F)",
    y = "Frequency"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold")
  )
```
- Looks Gaussian ish
- Lets do more tests for normality 

- Basic summary stats
```{r histogram}
temp_summary <- weather_data %>%
  summarise(
    n = n(),
    min = min(avg_temp),
    q1 = quantile(avg_temp, 0.25),
    median = median(avg_temp),
    mean = mean(avg_temp),
    q3 = quantile(avg_temp, 0.75),
    max = max(avg_temp),
    range = max(avg_temp) - min(avg_temp),
    sd = sd(avg_temp),
    cv = sd(avg_temp) / mean(avg_temp) * 100,
    iqr = IQR(avg_temp),
    skewness = (mean(avg_temp) - median(avg_temp)) / sd(avg_temp)
  )

print(temp_summary)
```

- Bayesian model fitting (will become clearer why at conclusion of this section -- rabbit hole!)
```{r histogram}
model_intervals <- brm(
  avg_temp ~ 1,
  data = weather_data,
  family = student(),
  chains = 4,
  iter = 2000,
  seed = 123
) %>%
  spread_draws(b_Intercept, sigma, nu) %>%
  median_qi(b_Intercept, sigma, nu, .width = c(0.95, 0.89, 0.50))

print(model_intervals)
```

#### Assessment of normality

```{r histogram}
# Create data frame for temperature analysis
temp_analysis <- data.frame(avg_temp = weather_data$avg_temp)

# Calculate statistics and prepare for Q-Q plot
temp_analysis <- temp_analysis %>%
  arrange(avg_temp) %>%
  mutate(
    row_index = row_number(),
    standardised_temp = scale(avg_temp)[,1],  # Using scale() for standardization
    theoretical_quantiles = qnorm(ppoints(n())[row_index]),
    residuals = standardised_temp - theoretical_quantiles
  )

# Display first 5 rows with proper dplyr select
head(temp_analysis, 5) %>%
  dplyr::select(row_index, avg_temp, standardised_temp, theoretical_quantiles, residuals)

# Generate simulated normal data for comparison
set.seed(123)  # For reproducibility
simulated_normal <- rnorm(n = nrow(temp_analysis))  # Standard normal for comparison

# Create data frame for simulated analysis
simulated_analysis <- data.frame(
  sim_temp = simulated_normal
) %>%
  mutate(
    standardised_temp = scale(sim_temp)[,1],
    theoretical_quantiles = qnorm(ppoints(length(sim_temp))),
    residuals = standardised_temp - theoretical_quantiles
  )

# Histogram of Residuals for Actual Data
hist_actual <- ggplot(temp_analysis, aes(x = residuals)) +
  geom_histogram(bins = 20, fill = "blue", colour = "black", alpha = 0.6) +
  labs(
    title = "Histogram of Residuals: Actual Data",
    x = "Residuals (Standardised Temp - Theoretical)",
    y = "Frequency"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 12),
    axis.title = element_text(face = "bold", size = 10),
    axis.text = element_text(size = 8),
    plot.margin = margin(5, 5, 5, 5)
  ) +
  coord_cartesian(xlim = c(-3, 3))

# Histogram of Residuals for Simulated Normal Data
hist_simulated <- ggplot(simulated_analysis, aes(x = residuals)) +
  geom_histogram(bins = 20, fill = "green", colour = "black", alpha = 0.6) +
  labs(
    title = "Histogram of Residuals: Simulated Normal Data",
    x = "Residuals (Standardised Temp - Theoretical)",
    y = "Frequency"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 12),
    axis.title = element_text(face = "bold", size = 10),
    axis.text = element_text(size = 8),
    plot.margin = margin(5, 5, 5, 5)
  ) +
  coord_cartesian(xlim = c(-3, 3))

# Arrange plots side by side
library(gridExtra)
grid.arrange(hist_actual, hist_simulated, ncol = 2, widths = c(1, 1))
```
- Remarkably similar! 


```{r histogram}
# Q-Q Plot for Actual Data
qq_actual <- ggplot(temp_analysis, aes(sample = avg_temp)) +
  stat_qq(color = "blue", alpha = 0.6) +
  stat_qq_line(color = "red", linetype = "dashed") +
  labs(
    title = "Q-Q Plot: Actual Average Temperature",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold")
  )

# Q-Q Plot for Simulated Data
qq_simulated <- ggplot(simulated_analysis, aes(sample = sim_temp)) +
  stat_qq(color = "green", alpha = 0.6) +
  stat_qq_line(color = "red", linetype = "dashed") +
  labs(
    title = "Q-Q Plot: Simulated Normal Data",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold")
  )

# Display side by side
grid.arrange(qq_actual, qq_simulated, ncol = 2, widths = c(1, 1))
```
- Not Soooo different to be honest (BUT could be an x-direction squish distorting things so make sure you view this in pop out terminal window or whatever)
- I guess this kind of aligns with the non-continuous nature of the data, 
- The lower tail (left side) shows points falling below the line, indicating more extreme cold values than would be expected in a normal distribution
- The middle section roughly follows the line
- The upper tail (right side) shows points falling above the line, indicating more extreme warm values than would be expected
- This S-shaped pattern suggests that your temperature data has a bimodal or multimodal distribution, which aligns with what we might expect for US climate data. This makes sense conceptually - the US spans multiple climate zones from very cold northern regions to very warm southern regions, leading to clusters of cities with similar temperature profiles rather than a smooth normal distribution.

```{r histogram}
# Scatter Plot for Actual Data
scatter_actual <- ggplot(temp_analysis, aes(x = theoretical_quantiles, y = standardised_temp)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Actual: Theoretical vs. Actual Quantiles",
    x = "Theoretical Quantiles (Normal Distribution)",
    y = "Standardised Average Temperature"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold")
  ) +
  coord_fixed(ratio = 1)

# Scatter Plot for Simulated Normal Data
scatter_simulated <- ggplot(simulated_analysis, aes(x = theoretical_quantiles, y = standardised_temp)) +
  geom_point(color = "green", alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Simulated: Theoretical vs. Actual Quantiles",
    x = "Theoretical Quantiles (Normal Distribution)",
    y = "Standardised Simulated Temperature"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold")
  ) +
  coord_fixed(ratio = 1)

grid.arrange(scatter_actual, scatter_simulated, ncol = 2, widths = c(1, 1))
```
- Actual (left), Simulated (Right) seem (I mean surely I should be able to say something more "precise" than visually vibes based) similar to me
- Line of Agreement (y = x): The red dashed line shows where points would lie if avg_temp were perfectly normal.
- Middle Range (x: -1 to 1): Points close to the line suggest the central part of the data is approximately normal.
- Tails (x < -1 or x > 1):
  - Below Line (Lower Tail): More extreme low values than expected -> heavy lower tail.
  - Above Line (Upper Tail): More extreme high values than expected -> heavy upper tail.
- S-Shape Pattern: Points below the line at the lower tail, near the line in the middle, above the line at the upper tail -> heavy-tailed (leptokurtic) distribution.
- Random Scatter?: Systematic S-shape means it's not random; indicates non-normality due to heavy tails.
- Implication: Data isn't fully normal; consider transformations or non-parametric methods if normality is required. 
- Could be the result of a few different distributions combined

```{r histogram}
# Calculate measures of location and spread
temp_summary <- weather_data %>%
  summarise(
    n = n(),
    min = min(avg_temp),
    q1 = quantile(avg_temp, 0.25),
    median = median(avg_temp),
    mean = mean(avg_temp),
    q3 = quantile(avg_temp, 0.75),
    max = max(avg_temp),
    range = max(avg_temp) - min(avg_temp),
    sd = sd(avg_temp),
    cv = sd(avg_temp) / mean(avg_temp) * 100, # coefficient of variation
    iqr = IQR(avg_temp),
    skewness = (mean(avg_temp) - median(avg_temp)) / sd(avg_temp) # rough measure of skewness
  )

knitr::kable(temp_summary, 
             caption = "Summary statistics for average temperature",
             digits = 3)
```

**NOTES:**
- Mean (50.77) vs. Median (49.681): The mean is slightly higher than the median, which aligns with the positive skewness (0.122). This suggests a slight right skew, meaning the right tail (higher values) is longer or fatter than the left tail.
- Standard Deviation (8.947): The SD indicates moderate variability around the mean. The coefficient of variation (CV = 17.622%) confirms this, as a CV around 10-20% suggests moderate relative variability for temperature data.
- IQR (11.05): The interquartile range shows the spread of the middle 50% of the data. It's relatively small compared to the range (52.509), indicating that the bulk of the data is clustered, but the tails (min and max) are far apart, supporting the idea of extreme values.
- Min (23.399) and Max (75.908):
The minimum (23.399) is much lower than the first quartile (45.148), a difference of 45.148 - 23.399 = 21.749. This suggests the lower tail extends quite far, consistent with your Q-Q plot observation of a single point significantly below the line.
- The maximum (75.908) is farther from the third quartile (56.198), a difference of 75.908 - 56.198 = 19.71, indicating a long upper tail, which aligns with the heavier upper tail seen in the Q-Q plot.
- Range (52.509): The large range relative to the IQR (11.05) indicates that the extremes (min and max) are driving much of the variability, supporting the presence of heavy tails.
- A skewness of 0.122 is slightly positive, indicating a mild right skew. This is consistent with the Q-Q plot's S-shape, where the upper tail (higher values) is heavier (above the line) and the lower tail has an extreme point (below the line).
- While 0.122 is close to 0 (symmetric), it suggests the distribution isn't perfectly symmetric, which could contribute to the borderline Shapiro-Wilk p-value (0.057).
- A sample size of 165 is moderate. The Shapiro-Wilk test's power to detect non-normality increases with sample size, but with n = 165, it may still lack power to detect subtle deviations (like mild heavy tails or a single outlier), which explains the borderline p-value.


```{r histogram}
temp_analysis <- temp_analysis %>%
  arrange(avg_temp) %>%
  mutate(
    row_index = row_number(),
    standardised_temp = (avg_temp - mean(avg_temp, na.rm = TRUE)) / sd(avg_temp, na.rm = TRUE),
    theoretical_quantiles = qnorm(ppoints(n())[row_index]),  # Ensure correct ordering
    residuals = standardised_temp - theoretical_quantiles
  )

# Display first 5 rows with proper column selection
head(temp_analysis, 5) %>%
  dplyr::select(row_index, avg_temp, standardised_temp, theoretical_quantiles, residuals)
```


**Simulated Data:**
- The Q-Q plot and scatter plot for the simulated data showed points closely following the line, and the histogram of residuals was more bell-shaped, as expected for a normal distribution.

**Conflict Between Test and Visuals:**
- The Shapiro-Wilk test (p-value = 0.057) suggests the actual data is normal at α = 0.05, but the visual evidence (S-shaped Q-Q plot) indicates heavy tails, a sign of non-normality.
- Sample Size: The Shapiro-Wilk test's sensitivity to deviations from normality depends on sample size. With a smaller sample, the test may lack power to detect subtle deviations (like heavy tails). With a larger sample, even small deviations can lead to rejection of H₀.
- p-value Near the Threshold: The p-value of 0.057 is very close to the 0.05 threshold. This borderline result means the test is on the edge of rejecting normality, and the visual evidence of heavy tails should not be ignored.
- The Shapiro-Wilk test is sensitive to various departures from normality (e.g., skewness, kurtosis), but heavy tails might not be extreme enough in your data to push the p-value below 0.05.


- Advanced QQ plot for outliers
```{r histogram}
# Define a threshold for outliers (e.g., top/bottom 1% of absolute residuals)
outlier_threshold <- quantile(abs(temp_analysis$residuals), 0.99)
temp_analysis <- temp_analysis %>%
  mutate(outlier = abs(residuals) > outlier_threshold)

# Enhanced Q-Q Plot with highlighted outliers
ggplot(temp_analysis, aes(sample = avg_temp)) +
  stat_qq(aes(colour = outlier), alpha = 0.6) +
  stat_qq_line(colour = "red", linetype = "dashed") +
  scale_colour_manual(values = c("FALSE" = "blue", "TRUE" = "orange")) +
  labs(
    title = "Q-Q Plot: Actual Average Temperature with Outliers Highlighted",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles",
    colour = "Outlier (Top/Bottom 1% Residuals)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 12),
    axis.title = element_text(face = "bold", size = 10),
    axis.text = element_text(size = 8),
    legend.position = "bottom"
  ) 
```


### Box Plot of Average Temperatures 

```{r histogram}
# Create boxplot for additional visualisation of spread
ggplot(weather_data, aes(y = avg_temp)) +
  geom_boxplot(fill = "steelblue", alpha = 0.7) +
  labs(
    title = "Boxplot of Average Temperatures",
    y = "Average Temperature (°F)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title = element_text(face = "bold")
  )
```


- Check for multimodality with kernel density plot
```{r histogram}
ggplot(weather_data, aes(x = avg_temp)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_rug() +
  labs(title = "Kernel Density Plot of Average Temperature",
       x = "Average Temperature (°F)",
       y = "Density") +
  theme_minimal()
```

- Examine skewness and kurtosis more precisely
```{r histogram}
skew <- skewness(weather_data$avg_temp)
kurt <- kurtosis(weather_data$avg_temp)
cat("Skewness:", skew, "\n")
cat("Kurtosis:", kurt, "\n")
cat("Normal distribution has skewness = 0 and kurtosis = 3\n")
```

Skewness: 0.3555469 
Kurtosis: 3.313368 
Normal distribution has skewness = 0 and kurtosis = 3


### Bayesian Analysis for Parameters
- Le Bayesian-Laplacian inverse probabilities methods for adducing an parameters
- Lets fit a robust Student's t model to account for the heavy tails we observed
-   formula = avg_temp ~ 1,  # Just modeling the distribution of temperature
-   family = student,        # Student's t distribution for heavy tails
-   data = weather_data,
-   chains = 4,             # Number of Markov chains
-   iter = 2000,            # Number of iterations per chain
-   warmup = 1000,          # Number of warmup iterations
-   seed = 123              # For reproducibility
```{r histogram}
temp_model <- brm(
  formula = avg_temp ~ 1,  
  family = student,        
  data = weather_data,
  chains = 4,             
  iter = 2000,            
  warmup = 1000,          
  seed = 123              
)

summary(temp_model)

# Posterior distributions
plot(temp_model)

# Compare our model to the actual data
pp_check(temp_model, ndraws = 100)
```

- Credible intervals generated earlier
```{r histogram}
print(model_intervals)
```

```{r histogram}
interpret_credible_intervals <- function(model_intervals) {
  cat("=== BAYESIAN CREDIBLE INTERVALS INTERPRETATION ===\n\n")
  cat("- Bayesian methods are the based and stat-pilled way to vibe your way to answers")
  
  format_temp_range <- function(lower, upper) {
    return(sprintf("%.1f°F to %.1f°F", lower, upper))
  }
  get_uncertainty_level <- function(width) {
    if (width >= 0.95) return("very high confidence")
    if (width >= 0.89) return("high confidence")
    if (width >= 0.50) return("moderate confidence")
    return("low confidence")
  }
  for(i in 1:nrow(model_intervals)) {
    width <- model_intervals$.width[i]
    percentage <- width * 100
    cat(sprintf("\n%d%% Credible Interval (%s):\n", 
                percentage, 
                get_uncertainty_level(width)))
    cat("Mean Temperature:\n")
    cat(sprintf("  - Range: %s\n", format_temp_range(model_intervals$b_Intercept.lower[i], model_intervals$b_Intercept.upper[i])))
    cat(sprintf("  - Interpretation: We can be %d%% confident that the true population mean\n temperature falls within this range\n",  percentage))
    cat("Variability (Standard Deviation):\n")
    cat(sprintf("  - Range: %s\n", format_temp_range(model_intervals$sigma.lower[i], model_intervals$sigma.upper[i])))
    cat(sprintf("  - Interpretation: We can be %d%% confident that the true population\n    standard deviation falls within this range\n", percentage))
    cat("Degrees of Freedom (nu):\n")
    cat(sprintf("  - Range: %.1f to %.1f\n", model_intervals$nu.lower[i], model_intervals$nu.upper[i]))
    # Degrees of freedom (I try not to think about what this means too hard)
    nu_interpretation <- if(model_intervals$nu[i] > 30) {
      "suggesting the distribution is very close to normal"
    } else if(model_intervals$nu[i] > 10) {
      "indicating moderately heavy tails compared to a normal distribution"
    } else {
      "indicating substantially heavy tails compared to a normal distribution"
    }
    cat(sprintf("  - Interpretation: %s\n", nu_interpretation))
    cat("\n", rep("-", 70), "\n", sep="")
  }
  cat("\nOVERALL MODEL ASSESSMENT:\n")
  cat("1. Distribution Shape: ", 
      if(median(model_intervals$nu) > 30) {
        "Approximately normal"
      } else if(median(model_intervals$nu) > 10) {
        "Slightly heavy-tailed normal"
      } else {
        "Heavy-tailed"
      }, "\n")
  median_temp <- median(model_intervals$b_Intercept)
  median_sigma <- median(model_intervals$sigma)
  cat(sprintf("2. Central Tendency: Most temperatures fall within %.1f°F to %.1f°F\n", median_temp - 2*median_sigma, median_temp + 2*median_sigma))
  cat("3. Model Reliability: ", 
      if(all(model_intervals$nu.lower > 4)) {
        "High - parameters are well-estimated with reasonable uncertainty"
      } else {
        "Moderate - some parameters show substantial uncertainty"
      }, "\n")
}

interpret_credible_intervals(model_intervals)
```


```{r histogram}
# Visualize the intervals
ggplot(weather_data, aes(x = avg_temp)) +
  stat_density(aes(color = "Observed"), geom = "line") +
  stat_function(
    fun = function(x) dt((x - median(model_intervals$b_Intercept)) / 
                        median(model_intervals$sigma), 
                        df = median(model_intervals$nu)),
    aes(color = "Model Fit")
  ) +
  geom_vline(data = model_intervals, 
             aes(xintercept = b_Intercept, linetype = "Mean"),
             color = "red") +
  geom_vline(data = model_intervals, 
             aes(xintercept = b_Intercept - sigma, linetype = "±1 SD"),
             color = "blue") +
  geom_vline(data = model_intervals, 
             aes(xintercept = b_Intercept + sigma, linetype = "±1 SD"),
             color = "blue") +
  labs(
    title = "Temperature Distribution with Credible Intervals",
    x = "Temperature (°F)",
    y = "Density"
  ) +
  theme_minimal()
```


### Section Conclusion

```{r histogram}
knitr::kable(temp_summary, 
             caption = "Summary statistics for average temperature",
             col.names = c("N", "Min", "Q1", "Median", "Mean", "Q3", "Max", 
                          "Range", "SD", "CV%", "IQR", "Skewness"),
             digits = 2)
```

- Conclusion using actual values
```{r histogram}
generate_temperature_summary <- function(temp_summary, model_intervals) {
  cat("### Summary of Average Temperature Analysis\n\n")
  cat("#### 1. Measures of Location\n")
  cat(sprintf("- **Mean**: %.2f°F\n", temp_summary$mean))
  cat(sprintf("- **Median**: %.2f°F\n", temp_summary$median))
  cat(sprintf("- **Quartiles**:\n"))
  cat(sprintf("  - Q1 (25th percentile): %.2f°F\n", temp_summary$q1))
  cat(sprintf("  - Q3 (75th percentile): %.2f°F\n", temp_summary$q3))
  cat(sprintf("- **Range**: %.2f°F to %.2f°F\n\n", temp_summary$min, temp_summary$max))
  cat("#### 2. Measures of Spread\n")
  cat(sprintf("- **Standard Deviation**: %.3f°F\n", temp_summary$sd))
  cat(sprintf("- **Interquartile Range (IQR)**: %.2f°F\n", temp_summary$iqr))
  cat(sprintf("- **Range**: %.2f°F\n", temp_summary$range))
  cat(sprintf("- **Coefficient of Variation**: %.3f%%\n\n", temp_summary$cv))
  cat("#### 3. Distribution Characteristics\n")
  cat(sprintf("- **Shape**: %s (skewness = %.3f)\n", ifelse(temp_summary$skewness > 0, "Right-skewed", "Left-skewed"), temp_summary$skewness))
  cat("\n#### 4. Bayesian Analysis Results\n")
  cat(sprintf("- **Mean Temperature (95%% CI)**: %.2f°F to %.2f°F\n",model_intervals$b_Intercept.lower[1], model_intervals$b_Intercept.upper[1]))
  cat(sprintf("- **Standard Deviation (95%% CI)**: %.2f°F to %.2f°F\n", model_intervals$sigma.lower[1], model_intervals$sigma.upper[1]))
  cat(sprintf("- **Distribution Shape**: Student's t with df ≈ %.2f (95%% CI: %.2f to %.2f)\n\n", model_intervals$nu[1], model_intervals$nu.lower[1], model_intervals$nu.upper[1]))
  
  cat("#### 5. Key Findings\n")
  cat("1. The distribution is ", 
      ifelse(model_intervals$nu[1] > 30, "approximately normal",
             ifelse(model_intervals$nu[1] > 10, "slightly heavy-tailed",
                    "heavily heavy-tailed")), "\n")
  cat(sprintf("2. There is a %s skew (%.3f), indicating %s\n",
              ifelse(temp_summary$skewness > 0, "right", "left"),
              temp_summary$skewness,
              ifelse(temp_summary$skewness > 0, 
                     "more extreme high temperatures than low",
                     "more extreme low temperatures than high")))
  cat(sprintf("3. The central 50%% of temperatures fall within a %.2f°F range\n",
              temp_summary$iqr))
  cat(sprintf("4. The coefficient of variation of %.2f%% indicates %s relative variability\n\n",
              temp_summary$cv,
              ifelse(temp_summary$cv < 10, "low",
                     ifelse(temp_summary$cv < 20, "moderate", "high"))))
  
  cat("#### 6. Implications for Modeling\n")
  cat(sprintf("1. %s distribution approximation is adequate\n",
              ifelse(model_intervals$nu[1] > 30, "A normal",
                     "A Student's t")))
  cat(sprintf("2. The %.2f%% coefficient of variation indicates %s variability\n",
              temp_summary$cv,
              ifelse(temp_summary$cv < 10, "low",
                     ifelse(temp_summary$cv < 20, "moderate", "high"))))
  cat(sprintf("3. The %s skew suggests %s when robust estimates are needed\n",
              ifelse(abs(temp_summary$skewness) < 0.2, "minimal",
                     ifelse(abs(temp_summary$skewness) < 0.5, "moderate", "substantial")),
              ifelse(abs(temp_summary$skewness) < 0.2, "mean-based methods are appropriate",
                     "using median-based methods")))
}

# Generate the summary
generate_temperature_summary(temp_summary, model_intervals)
```

### Summary of Average Temperature Analysis

#### 1. Measures of Location
- **Mean**: 50.77°F
- **Median**: 49.68°F
- **Quartiles**:
  - Q1 (25th percentile): 45.15°F
  - Q3 (75th percentile): 56.20°F
- **Range**: 23.40°F to 75.91°F

#### 2. Measures of Spread
- **Standard Deviation**: 8.947°F
- **Interquartile Range (IQR)**: 11.05°F
- **Range**: 52.51°F
- **Coefficient of Variation**: 17.622%

#### 3. Distribution Characteristics
- **Shape**: Right-skewed (skewness = 0.122)

#### 4. Bayesian Analysis Results
- **Mean Temperature (95%% CI)**: 49.14°F to 51.93°F
- **Standard Deviation (95%% CI)**: 7.16°F to 9.64°F
- **Distribution Shape**: Student's t with df ≈ 17.62 (95% CI: 5.58 to 53.86)

#### 5. Key Findings
1. The distribution is  slightly heavy-tailed 
2. There is a right skew (0.122), indicating more extreme high temperatures than low
3. The central 50%% of temperatures fall within a 11.05°F range
4. The coefficient of variation of 17.62% indicates moderate relative variability

#### 6. Implications for Modeling
1. A Student's t distribution approximation is adequate
2. The 17.62% coefficient of variation indicates moderate variability
3. The minimal skew suggests mean-based methods are appropriate when robust estimates are needed


```{r histogram}
actual_mean <- temp_summary$mean
actual_sd <- temp_summary$sd
# Degrees of freedom from Bayesian model
actual_nu <- model_intervals$nu[1]  

ggplot(data.frame(x = c(actual_mean - 3*actual_sd, 
                       actual_mean + 3*actual_sd)), aes(x)) +
  stat_function(fun = dnorm, 
                args = list(mean = actual_mean, 
                          sd = actual_sd),
                aes(color = "Normal"),
                size = 1) +
  stat_function(fun = function(x) dt((x - actual_mean)/actual_sd, 
                                    df = actual_nu)/(actual_sd),
                aes(color = "Student's t"),
                size = 1) +
  geom_density(data = weather_data, 
               aes(x = avg_temp, color = "Actual Data"),
               size = 1) +
  labs(title = "Comparison of Fitted Distributions to Actual Temperature Data",
       subtitle = sprintf("Student's t (df = %.1f) vs Normal Distribution", actual_nu),
       x = "Temperature (°F)",
       y = "Density",
       color = "Distribution") +
  scale_color_manual(values = c("Actual Data" = "black",
                               "Normal" = "blue",
                               "Student's t" = "red")) +
  theme_minimal() +
  theme(legend.position = "bottom")
```
- This visualisation is pretty cool. I don't really feel comfortable using a Gaussian or Students T as a theoretical model based off of those differences to be honest. 
- Particularly the way that peak tilts off to the left

```{r histogram}
# Create temperature bins/regions
temp_regions <- weather_data %>%
  summarise(
    low_temp = min(avg_temp),
    q1 = quantile(avg_temp, 0.25),
    median = median(avg_temp),
    q3 = quantile(avg_temp, 0.75),
    high_temp = max(avg_temp)
  ) %>%
  gather(region, temp_value)

# Calculate actual proportions in each region
actual_props <- weather_data %>%
  mutate(region = case_when(
    avg_temp < temp_regions$temp_value[temp_regions$region == "q1"] ~ "Left Tail",
    avg_temp < temp_regions$temp_value[temp_regions$region == "median"] ~ "Left Center",
    avg_temp < temp_regions$temp_value[temp_regions$region == "q3"] ~ "Right Center",
    TRUE ~ "Right Tail"
  )) %>%
  group_by(region) %>%
  summarise(
    actual_prop = n()/nrow(weather_data),
    mean_temp = mean(avg_temp)
  )

# Calculate theoretical proportions for normal distribution
normal_props <- data.frame(
  region = actual_props$region,
  normal_prop = c(
    pnorm(temp_regions$temp_value[2], mean = temp_summary$mean, sd = temp_summary$sd),
    pnorm(temp_regions$temp_value[3], mean = temp_summary$mean, sd = temp_summary$sd) - 
      pnorm(temp_regions$temp_value[2], mean = temp_summary$mean, sd = temp_summary$sd),
    pnorm(temp_regions$temp_value[4], mean = temp_summary$mean, sd = temp_summary$sd) - 
      pnorm(temp_regions$temp_value[3], mean = temp_summary$mean, sd = temp_summary$sd),
    1 - pnorm(temp_regions$temp_value[4], mean = temp_summary$mean, sd = temp_summary$sd)
  )
)

# Calculate theoretical proportions for t distribution
t_props <- data.frame(
  region = actual_props$region,
  t_prop = c(
    pt((temp_regions$temp_value[2] - temp_summary$mean)/temp_summary$sd, df = model_intervals$nu[1]),
    pt((temp_regions$temp_value[3] - temp_summary$mean)/temp_summary$sd, df = model_intervals$nu[1]) - 
      pt((temp_regions$temp_value[2] - temp_summary$mean)/temp_summary$sd, df = model_intervals$nu[1]),
    pt((temp_regions$temp_value[4] - temp_summary$mean)/temp_summary$sd, df = model_intervals$nu[1]) - 
      pt((temp_regions$temp_value[3] - temp_summary$mean)/temp_summary$sd, df = model_intervals$nu[1]),
    1 - pt((temp_regions$temp_value[4] - temp_summary$mean)/temp_summary$sd, df = model_intervals$nu[1])
  )
)

comparison_df <- actual_props %>%
  left_join(normal_props, by = "region") %>%
  left_join(t_props, by = "region") %>%
  mutate(
    normal_diff = normal_prop - actual_prop,
    t_diff = t_prop - actual_prop
  )

# Pretty print the results
knitr::kable(comparison_df %>%
  dplyr::select(region, actual_prop, normal_prop, t_prop, normal_diff, t_diff) %>%
  mutate(across(where(is.numeric), ~round(., 3))),
  col.names = c("Region", "Actual Proportion", "Normal Prop", "Student's t Prop", 
                "Normal Difference", "t Difference"),
  caption = "Comparison of Regional Proportions Between Actual and Theoretical Distributions")
```



```{r}
bayesian_intervals_plot <- ggplot(weather_data, aes(x = avg_temp)) +
  stat_density(aes(color = "Observed"), geom = "line") +
  stat_function(
    fun = function(x) dt((x - median(model_intervals$b_Intercept)) / 
                        median(model_intervals$sigma), 
                        df = median(model_intervals$nu)),
    aes(color = "Model Fit")
  ) +
  geom_vline(data = model_intervals, 
             aes(xintercept = b_Intercept, linetype = "Mean"),
             color = "red") +
  geom_vline(data = model_intervals, 
             aes(xintercept = b_Intercept - sigma, linetype = "±1 SD"),
             color = "blue") +
  geom_vline(data = model_intervals, 
             aes(xintercept = b_Intercept + sigma, linetype = "±1 SD"),
             color = "blue") +
  labs(
    title = "Temperature Distribution with Credible Intervals",
    x = "Temperature (°F)",
    y = "Density"
  ) +
  theme_minimal()

distribution_comparison <- ggplot(data.frame(x = c(actual_mean - 3*actual_sd, 
                                                 actual_mean + 3*actual_sd)), aes(x)) +
  stat_function(fun = dnorm, 
                args = list(mean = actual_mean, 
                          sd = actual_sd),
                aes(color = "Normal"),
                size = 1) +
  stat_function(fun = function(x) dt((x - actual_mean)/actual_sd, 
                                    df = actual_nu)/(actual_sd),
                aes(color = "Student's t"),
                size = 1) +
  geom_density(data = weather_data, 
               aes(x = avg_temp, color = "Actual Data"),
               size = 1) +
  labs(title = "Comparison of Fitted Distributions to Actual Temperature Data",
       subtitle = sprintf("Student's t (df = %.1f) vs Normal Distribution", actual_nu),
       x = "Temperature (°F)",
       y = "Density",
       color = "Distribution") +
  scale_color_manual(values = c("Actual Data" = "black",
                               "Normal" = "blue",
                               "Student's t" = "red")) +
  theme_minimal() +
  theme(legend.position = "bottom")

# Collect ALL plots into a list
exploration_plots <- list(
  "temp_distribution" = ggplot(weather_data, aes(x = avg_temp)) +
    geom_histogram(binwidth = 2, fill = "steelblue", color = "white", alpha = 0.7) +
    labs(title = "Distribution of Average Temperatures", x = "Average Temperature (°F)", y = "Count") +
    theme_minimal(),
  
  "qq_plots" = grid.arrange(qq_actual, qq_simulated, ncol = 2, widths = c(1, 1)),
  
  "scatter_plots" = grid.arrange(scatter_actual, scatter_simulated, ncol = 2, widths = c(1, 1)),
  
  "residual_histograms" = grid.arrange(hist_actual, hist_simulated, ncol = 2, widths = c(1, 1)),
  
  "koppen_violin" = ggplot(weather_data, aes(x = reorder(koppen, avg_temp, FUN = median), 
                                           y = avg_temp, 
                                           fill = koppen)) +
    geom_violin(alpha = 0.7, scale = "width") +
    geom_boxplot(width = 0.2, alpha = 0.5, fill = "white") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)),
    
  "bayesian_intervals" = bayesian_intervals_plot,
  
  "distribution_comparison" = distribution_comparison,
  
  "bayesian_posterior" = plot(temp_model),
  
  "posterior_predictive" = pp_check(temp_model, ndraws = 100)
)

# Set custom dimensions for specific plots
attr(exploration_plots$qq_plots, "width") <- 12
attr(exploration_plots$qq_plots, "height") <- 6
attr(exploration_plots$scatter_plots, "width") <- 12
attr(exploration_plots$scatter_plots, "height") <- 6
attr(exploration_plots$bayesian_intervals, "width") <- 10
attr(exploration_plots$bayesian_intervals, "height") <- 8
attr(exploration_plots$distribution_comparison, "width") <- 12
attr(exploration_plots$distribution_comparison, "height") <- 8
attr(exploration_plots$bayesian_posterior, "width") <- 12
attr(exploration_plots$bayesian_posterior, "height") <- 10
attr(exploration_plots$posterior_predictive, "width") <- 12
attr(exploration_plots$posterior_predictive, "height") <- 8

save_visualisations(exploration_plots, prefix = "exploration")
```


```{r}
# Create posterior plots using brms-specific methods
posterior_plots <- list(
  # Basic posterior distributions
  "posterior_distributions" = plot(temp_model),
  
  # Posterior predictive checks
  "posterior_predictive" = pp_check(temp_model, ndraws = 100),
  
  # Parameter estimates with uncertainty
  "parameter_estimates" = as_draws_df(temp_model) %>%
    dplyr::select("b_Intercept", "sigma", "nu") %>%
    tidyr::pivot_longer(everything(), names_to = "parameter", values_to = "value") %>%
    ggplot(aes(y = parameter, x = value)) +
    stat_halfeye() +
    labs(title = "Parameter Estimates with Uncertainty",
         x = "Value",
         y = "Parameter") +
    theme_minimal(),
  
  # Density plots of parameters
  "density_plots" = as_draws_df(temp_model) %>%
    dplyr::select("b_Intercept", "sigma", "nu") %>%
    tidyr::pivot_longer(everything(), names_to = "parameter", values_to = "value") %>%
    ggplot(aes(x = value, fill = parameter)) +
    geom_density(alpha = 0.5) +
    facet_wrap(~parameter, scales = "free") +
    labs(title = "Parameter Posterior Distributions",
         x = "Value",
         y = "Density") +
    theme_minimal(),
  
  # Trace plots
  "trace_plots" = plot(temp_model, N = 4, ask = FALSE)
)

# Set custom dimensions for posterior plots
attr(posterior_plots$posterior_distributions, "width") <- 12
attr(posterior_plots$posterior_distributions, "height") <- 8
attr(posterior_plots$posterior_predictive, "width") <- 10
attr(posterior_plots$posterior_predictive, "height") <- 6
attr(posterior_plots$parameter_estimates, "width") <- 8
attr(posterior_plots$parameter_estimates, "height") <- 6
attr(posterior_plots$density_plots, "width") <- 12
attr(posterior_plots$density_plots, "height") <- 8
attr(posterior_plots$trace_plots, "width") <- 12
attr(posterior_plots$trace_plots, "height") <- 10

# Save posterior plots
save_visualisations(posterior_plots, prefix = "posterior")
  
```


Let me know if you want to adjust any